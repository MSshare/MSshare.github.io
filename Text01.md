# Task01 绪论与深度学习概述、数学基础

## 1 绪论与深度学习概述

### 1.1深度学习的起源与发展

#### 1 起源

    首先我们了解到深度学习是机器学习的一部分，要想了解深度学习的起源肯定要先去看一下机器学习的发展过程。
    在整个机器学习的发展过程中最重要也是最核心的就是神经网络的发展。
    当我们去查阅整个神经网络的历史时，不难发现，整个神经网络的发展经历了“三起两落”的发展过程。

#### 2 一起

    从1943年提出MCP神经元，到1957年单层感知机的实现。揭开了神经网络发展的序幕。
   
#### 3 一落

    然而在1969年时由Minsky和Seymour Papert在专著Perceptron中提出：
    “单层感知机不能解决XOR问题”的结论导致深度学习迎来第一次寒冬。
#### 4 二起

    这次下落一直持续的1986年反向传播算法的提出。反向传播算法解决了多层感知机的优化问题，使得深度学习得以继续发展。
    在这之后又相继提出了通用近似定理和卷积神经网络，LSTM网络也首次出现在人们面前。
    
#### 5 二落

    这次发展一直持续到1998年LeNet网络的提出。虽然LeNet网络能够实现很好的效果，但在当时它所消耗的算力也是十分惊人的。
    当时的计算机技术不足以支撑它商业化。至此深度学习又一次陷入窘境。从此一直沉寂了十几年。
    中间虽然也有一些好的优化方案提出。但最重要的算力问题一直都没得到解决。
#### 6 三起

    直到2012年AlexNet网络的提出以及它在ImageNet比赛中的亮眼表现才使得人们发现现代的计算机技术已经发展到了能够支撑大型网络算力的程度。
    当然这里也要感谢英伟达创始人黄仁勋的一次豪赌。
    CUDA的提出大大加快了深度学习算力提升的进程。
    从这以后各种网络开始兴起后面的VGGNet、GooleLeNet、ResNet以及再后面提出的GAN网络都对以前的模型做出来很大的优化。
    至今我们仍处在深度学习第三次兴起的过程中。
