# Task02 机器学习基础

## 1 数据集

一组记录的集合称为一个"数据集" (data set) ，
其中每条记录是关于一个事件或对象的描述，称为一个"示例" (instance) 或"样本" (samp1e)。
有时整个数据集亦称一个"样本"因为它可看作对样本空间的一个采样，
通过上下文可判断出"样本"是指单个示例还是数据集。

## 2 误差分析

### 2.1 留出法

留出法：直接将数据集D划分为两个互斥的集合，其中一个集合作为训练集S，
另一个作为训练集T。单次使用留出法得到的估计结果往往不够稳定可靠，
在使用留出法时，一般要采用若干次随机划分，重复进行实验评估后取平均值作为留出法的评估结果。
通常将2/3~4/5的样本用于训练，剩余样本用于测试。

### 2.2 交叉验证法

交叉验证法：先将数据集D划分为k个大小相似的互斥子集，然后，每次用k-1个子集的并集作为训练集，
余下的那个子集作为测试集；这样就可获得k组训练/测试集，从而可进行k次训练和测试，
最终返回的是这k个测试结果的均值。交叉验证法评估结果的稳定性和保真性在很大程度上取决于k的取值，
通常又称为“k折交叉验证”。与留出法相似，将数据集划分为k个子集同样存在多种划分方式，为减少因样本划分不同而引入的差别，
k折交叉验证通常要随机使用不同的划分重复p次，最终的评估结果是这p次k折交叉验证结果的均值。假定数据集中包含m个样本，
若令k=m，则得到了交叉验证法的一个特例：留一法。

### 2.3 自助法

自助法：为减少训练样本规模不同造成的影响，同时比较高效地进行实验估计。
自助法（bootstrapping）以自助采样法为基础。给定包含m个样本的数据集D，我们对它进行采样产生数据集D’：
每次随机从D中挑选一个样本，将其拷贝放入D’，然后再将该样本放回初始数据集中，使得该样本在下次采样时仍有可能被采到；
这个过程重复执行m次后，我们就得到了包含m个样本的数据集D’。显然，D中有一部分样本在D’中多次出现，而一部分样本不出现。
通过自助采样，初始数据集D中约有36.8%的样本未出现在采样数据集D’中。于是将D’用作训练集，D/D’用作测试集。这样的测试结果，亦称“包外估计”。

## 3 代表机器学习的方法

### 3.1 有监督学习

监督学习(supervised learning)：训练数据有标记信息，其中分类与回归属于监督学习。

### 3.2 无监督学习

无监督学习(unsupervised learning)：训练数据没有标记信息，代表有聚类。

